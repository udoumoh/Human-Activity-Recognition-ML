{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b718dc17-55be-4d99-b302-b98cadcf853c",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# Multi-Class Activity Classification — PySpark MLlib\n# ============================================================\n# Pipeline: StringIndexer → VectorAssembler → StandardScaler\n#           → Classifier\n#\n# Models : Logistic Regression, Random Forest,\n#          Multilayer Perceptron, Linear SVM (OneVsRest)\n# Tuning : CrossValidator  (3-fold)\n# Metrics: Accuracy, Weighted F1\n# ============================================================\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import DoubleType\nfrom pyspark.sql.functions import col\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import (\n    StringIndexer, IndexToString, VectorAssembler, StandardScaler,\n)\nfrom pyspark.ml.classification import (\n    LogisticRegression,\n    RandomForestClassifier,\n    MultilayerPerceptronClassifier,\n    LinearSVC,\n    OneVsRest,\n)\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import (\n    MulticlassClassificationEvaluator,\n)\n\nimport time\n\nspark = (\n    SparkSession.builder\n    .appName(\"PAMAP2_ModelTraining\")\n    .master(\"local[4]\")\n    .config(\"spark.driver.memory\", \"4g\")\n    .config(\"spark.sql.shuffle.partitions\", \"4\")\n    .config(\"spark.python.worker.reuse\", \"true\")\n    .getOrCreate()\n)\nspark.sparkContext.setLogLevel(\"WARN\")\nprint(f\"Spark version : {spark.version}\")"
  },
  {
   "cell_type": "code",
   "id": "jk18wgbs1b9",
   "source": "# ============================================================\n# 1. Load features and prepare label / feature columns\n# ============================================================\n\nINPUT_PATH = r\"C:/Users/johnu/Desktop/BigDataProject/data/pamap2_features.parquet\"\n\ndf = spark.read.parquet(INPUT_PATH)\nprint(f\"Loaded {df.count():,} rows  x  {len(df.columns)} columns\")\n\n# -- Identify feature columns (all DoubleType, excluding keys) -\nMETA = {\"subject_id\", \"activity_id\"}\nfeature_cols = sorted([\n    c for c in df.columns\n    if c not in META\n    and isinstance(df.schema[c].dataType, DoubleType)\n])\nprint(f\"Feature columns : {len(feature_cols)}\")\n\n# -- Replace NaN with 0 (stddev columns produce NaN for\n#    single-value windows) then drop any remaining nulls ------\nfrom pyspark.sql.functions import isnan, when\n\nfor c in feature_cols:\n    df = df.withColumn(c, when(isnan(col(c)), 0.0).otherwise(col(c)))\n\ndf_clean = df.na.drop(subset=feature_cols)\nprint(f\"After NaN-fix + null-drop : {df_clean.count():,} rows\")\n\n# -- Train / test split (80/20) --------------------------------\ntrain_df, test_df = df_clean.randomSplit([0.8, 0.2], seed=42)\ntrain_df.cache()\ntest_df.cache()\n\nprint(f\"\\nTrain : {train_df.count():,}\")\nprint(f\"Test  : {test_df.count():,}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "i8s043flzpl",
   "source": "# ============================================================\n# 2. Shared pipeline stages & evaluation helpers\n# ============================================================\n# These three stages are reused by every model:\n#   StringIndexer  -> maps activity_id (int) to 0-based label\n#   VectorAssembler -> packs feature columns into a Vector\n#   StandardScaler  -> zero-mean, unit-variance scaling\n#\n# The classifier is appended per-model to form the full Pipeline.\n# ============================================================\n\n# -- Label indexer ---------------------------------------------\nlabel_indexer = (\n    StringIndexer(inputCol=\"activity_id\", outputCol=\"label\")\n    .setHandleInvalid(\"keep\")\n)\n\n# -- Feature assembly ------------------------------------------\nassembler = VectorAssembler(\n    inputCols=feature_cols,\n    outputCol=\"features_raw\",\n    handleInvalid=\"keep\",\n)\n\n# -- Standard scaler -------------------------------------------\nscaler = StandardScaler(\n    inputCol=\"features_raw\",\n    outputCol=\"features\",\n    withMean=True,\n    withStd=True,\n)\n\n# -- Evaluators ------------------------------------------------\neval_accuracy = MulticlassClassificationEvaluator(\n    labelCol=\"label\", predictionCol=\"prediction\",\n    metricName=\"accuracy\",\n)\neval_f1 = MulticlassClassificationEvaluator(\n    labelCol=\"label\", predictionCol=\"prediction\",\n    metricName=\"f1\",\n)\n\n# -- Store results ---------------------------------------------\nresults = []\n\ndef evaluate_model(model_name, cv_model, test_data):\n    \"\"\"\n    Run the best model from CrossValidator on the test set,\n    compute accuracy and weighted-F1, store in results,\n    and print a summary.\n    \"\"\"\n    t0 = time.time()\n    predictions = cv_model.transform(test_data)\n    acc = eval_accuracy.evaluate(predictions)\n    f1  = eval_f1.evaluate(predictions)\n    elapsed = time.time() - t0\n\n    results.append({\n        \"model\": model_name,\n        \"accuracy\": round(acc, 4),\n        \"f1_weighted\": round(f1, 4),\n        \"eval_time_s\": round(elapsed, 1),\n    })\n\n    print(f\"\\n{'=' * 56}\")\n    print(f\"  {model_name}\")\n    print(f\"{'=' * 56}\")\n    print(f\"  Accuracy     : {acc:.4f}\")\n    print(f\"  Weighted F1  : {f1:.4f}\")\n    print(f\"  Eval time    : {elapsed:.1f}s\")\n    print(f\"{'=' * 56}\")\n\n    return predictions\n\nprint(\"Shared stages ready.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b6oizav1cc9",
   "source": "# ============================================================\n# 3. Logistic Regression (multinomial)\n# ============================================================\n\nlr = LogisticRegression(\n    featuresCol=\"features\",\n    labelCol=\"label\",\n    family=\"multinomial\",\n    maxIter=100,\n    elasticNetParam=0.0,\n)\n\nlr_pipeline = Pipeline(stages=[label_indexer, assembler, scaler, lr])\n\nlr_grid = (\n    ParamGridBuilder()\n    .addGrid(lr.regParam, [0.01, 0.1])\n    .build()\n)\n\nlr_cv = CrossValidator(\n    estimator=lr_pipeline,\n    estimatorParamMaps=lr_grid,\n    evaluator=eval_f1,\n    numFolds=3,\n    parallelism=1,\n    seed=42,\n)\n\nprint(f\"Logistic Regression -- grid size: {len(lr_grid)}, folds: 3\")\nt0 = time.time()\nlr_cv_model = lr_cv.fit(train_df)\nprint(f\"Training time: {time.time() - t0:.1f}s\")\n\nlr_preds = evaluate_model(\"Logistic Regression\", lr_cv_model, test_df)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "evyvu9ll457",
   "source": "# ============================================================\n# 4. Random Forest\n# ============================================================\n\nrf = RandomForestClassifier(\n    featuresCol=\"features\",\n    labelCol=\"label\",\n    seed=42,\n)\n\nrf_pipeline = Pipeline(stages=[label_indexer, assembler, scaler, rf])\n\nrf_grid = (\n    ParamGridBuilder()\n    .addGrid(rf.numTrees,  [20, 50])\n    .addGrid(rf.maxDepth,  [5])\n    .build()\n)\n\nrf_cv = CrossValidator(\n    estimator=rf_pipeline,\n    estimatorParamMaps=rf_grid,\n    evaluator=eval_f1,\n    numFolds=3,\n    parallelism=1,\n    seed=42,\n)\n\nprint(f\"Random Forest -- grid size: {len(rf_grid)}, folds: 3\")\nt0 = time.time()\nrf_cv_model = rf_cv.fit(train_df)\nprint(f\"Training time: {time.time() - t0:.1f}s\")\n\nrf_preds = evaluate_model(\"Random Forest\", rf_cv_model, test_df)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "a786e9y9jn6",
   "source": "# ============================================================\n# 5. Multilayer Perceptron (MLP) Classifier\n# ============================================================\n# Feed-forward neural network with configurable hidden layers.\n# Natively supports multi-class via softmax output layer.\n# ============================================================\n\nNUM_FEATURES = len(feature_cols)   # 172\nNUM_CLASSES  = train_df.select(\"activity_id\").distinct().count()\n\nmlp = MultilayerPerceptronClassifier(\n    featuresCol=\"features\",\n    labelCol=\"label\",\n    layers=[NUM_FEATURES, 64, NUM_CLASSES],\n    blockSize=128,\n    seed=42,\n)\n\nmlp_pipeline = Pipeline(stages=[label_indexer, assembler, scaler, mlp])\n\nmlp_grid = (\n    ParamGridBuilder()\n    .addGrid(mlp.maxIter, [50, 100])\n    .build()\n)\n\nmlp_cv = CrossValidator(\n    estimator=mlp_pipeline,\n    estimatorParamMaps=mlp_grid,\n    evaluator=eval_f1,\n    numFolds=3,\n    parallelism=1,\n    seed=42,\n)\n\nprint(f\"MLP -- grid size: {len(mlp_grid)}, folds: 3\")\nprint(f\"  Layers: [{NUM_FEATURES}, 64, {NUM_CLASSES}]\")\nt0 = time.time()\nmlp_cv_model = mlp_cv.fit(train_df)\nprint(f\"Training time: {time.time() - t0:.1f}s\")\n\nmlp_preds = evaluate_model(\"Multilayer Perceptron\", mlp_cv_model, test_df)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4zqgqvsk9fg",
   "source": "# ============================================================\n# 6. Linear SVM (OneVsRest for multi-class)\n# ============================================================\n# Spark's LinearSVC is binary-only.  We wrap it with OneVsRest\n# which trains one binary SVC per class and combines them.\n# ============================================================\n\nlsvc = LinearSVC(\n    featuresCol=\"features\",\n    labelCol=\"label\",\n    maxIter=50,\n)\n\novr = OneVsRest(\n    classifier=lsvc,\n    featuresCol=\"features\",\n    labelCol=\"label\",\n)\n\nsvm_pipeline = Pipeline(stages=[label_indexer, assembler, scaler, ovr])\n\nsvm_grid = (\n    ParamGridBuilder()\n    .addGrid(lsvc.regParam, [0.01, 0.1])\n    .build()\n)\n\nsvm_cv = CrossValidator(\n    estimator=svm_pipeline,\n    estimatorParamMaps=svm_grid,\n    evaluator=eval_f1,\n    numFolds=3,\n    parallelism=1,\n    seed=42,\n)\n\nprint(f\"Linear SVM (OVR) -- grid size: {len(svm_grid)}, folds: 3\")\nt0 = time.time()\nsvm_cv_model = svm_cv.fit(train_df)\nprint(f\"Training time: {time.time() - t0:.1f}s\")\n\nsvm_preds = evaluate_model(\"Linear SVM (OVR)\", svm_cv_model, test_df)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "a8zxscusuj8",
   "source": "# ============================================================\n# 7. Comparison summary\n# ============================================================\n\nfrom pyspark.sql import Row\n\ndf_results = spark.createDataFrame([Row(**r) for r in results])\ndf_results = df_results.select(\"model\", \"accuracy\", \"f1_weighted\", \"eval_time_s\")\n\nprint(\"=\" * 64)\nprint(\"  MODEL COMPARISON — PAMAP2 Activity Recognition\")\nprint(\"=\" * 64)\ndf_results.orderBy(col(\"f1_weighted\").desc()).show(truncate=False)\n\n# Identify best model\nbest = max(results, key=lambda r: r[\"f1_weighted\"])\nprint(f\"Best model by weighted-F1: {best['model']}\")\nprint(f\"  Accuracy    : {best['accuracy']}\")\nprint(f\"  Weighted F1 : {best['f1_weighted']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f5la88og31",
   "source": "# ============================================================\n# 8. Save the best model and results to disk\n# ============================================================\n\nimport json\n\nOUTPUT_DIR = r\"C:/Users/johnu/Desktop/BigDataProject/data\"\n\n# -- Save results as JSON --------------------------------------\nresults_path = f\"{OUTPUT_DIR}/model_results.json\"\nwith open(results_path, \"w\") as f:\n    json.dump(results, f, indent=2)\nprint(f\"Results saved to {results_path}\")\n\n# -- Save the best CrossValidator model ------------------------\nbest_models = {\n    \"Logistic Regression\":    lr_cv_model,\n    \"Random Forest\":          rf_cv_model,\n    \"Multilayer Perceptron\":  mlp_cv_model,\n    \"Linear SVM (OVR)\":       svm_cv_model,\n}\nbest_cv = best_models[best[\"model\"]]\nmodel_path = f\"{OUTPUT_DIR}/best_model\"\nbest_cv.bestModel.write().overwrite().save(model_path)\nprint(f\"Best model ({best['model']}) saved to {model_path}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}